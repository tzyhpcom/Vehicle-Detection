{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from keras import losses\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NOTE: the next import is only valid for scikit-learn version <= 0.17\n",
    "# for scikit-learn >= 0.18 use:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment functions\n",
    "\n",
    "# transform x y direction, input original rgb image\n",
    "def transform_image(image):\n",
    "    trans_range = 4\n",
    "    tx = trans_range*(np.random.uniform()-0.5)\n",
    "    ty = 2*(np.random.uniform()-0.5)\n",
    "    rows,cols,_ = image.shape\n",
    "    M = np.float32([[1,0,tx],[0,1,ty]])\n",
    "    image = cv2.warpAffine(image,M,(cols,rows))\n",
    "    return image\n",
    "\n",
    "# Horizontal Flip\n",
    "def flip_image(image):\n",
    "    # Horizontal Flip\n",
    "    image = cv2.flip(image, 1)\n",
    "    return image\n",
    "\n",
    "# adjust brightness\n",
    "def bright_image(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v = v.astype(np.float)\n",
    "#     v *= (np.random.uniform()+0.2)\n",
    "    v *= np.random.choice([0,8, 1, 1.2])\n",
    "    v[v>255] = 255\n",
    "    v[v<0] = 0\n",
    "    v = v.astype(np.uint8)\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    image_hsv = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2RGB)\n",
    "    return image_hsv\n",
    "\n",
    "# warp image\n",
    "def warp_image(img):\n",
    "    rows,cols,_ = img.shape\n",
    "    # random scaling coefficients\n",
    "    rndx = np.random.rand(3) - 0.5\n",
    "    rndx *= cols * 0.06   # this coefficient determines the degree of warping\n",
    "    rndy = np.random.rand(3) - 0.5\n",
    "    rndy *= rows * 0.06\n",
    "    # 3 starting points for transform, 1/4 way from edges\n",
    "    x1 = cols/4\n",
    "    x2 = 3*cols/4\n",
    "    y1 = rows/4\n",
    "    y2 = 3*rows/4\n",
    "\n",
    "    pts1 = np.float32([[y1,x1],\n",
    "                       [y2,x1],\n",
    "                       [y1,x2]])\n",
    "    pts2 = np.float32([[y1+rndy[0],x1+rndx[0]],\n",
    "                       [y2+rndy[1],x1+rndx[1]],\n",
    "                       [y1+rndy[2],x2+rndx[2]]])\n",
    "\n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "       \n",
    "    return dst\n",
    "\n",
    "# input rgb image\n",
    "def preprocess_image(image):\n",
    "    rows,cols,_ = image.shape\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     image = cv2.equalizeHist(image)\n",
    "#     image = image[50:rows-20, 0:cols]\n",
    "#     image = cv2.resize(image, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "    image = image/255.0 - 0.5\n",
    "#     image = np.expand_dims(image, axis=2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17760,)\n",
      "(17760,)\n"
     ]
    }
   ],
   "source": [
    "images_car = glob.glob('../vehicle_data/vehicles/*/*.png')\n",
    "images_nocar = glob.glob('../vehicle_data/non-vehicles/*/*.png')\n",
    "cars = []\n",
    "notcars = []\n",
    "\n",
    "for image in images_car:\n",
    "    cars.append(image)\n",
    "for image in images_nocar:\n",
    "    notcars.append(image)\n",
    "    \n",
    "X_ = np.hstack((cars, notcars))\n",
    "y_ = np.hstack((np.ones(len(cars)), np.zeros(len(notcars))))\n",
    "print(X_.shape)\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15984\n",
      "1776\n",
      "15984\n",
      "1776\n"
     ]
    }
   ],
   "source": [
    "labelencoder_y_1 = LabelEncoder()\n",
    "y_ = labelencoder_y_1.fit_transform(y_)\n",
    "\n",
    "X_, y_ = shuffle(X_, y_)\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.1, random_state=rand_state)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_samples(X_, y_, batch_size=32, if_train=False):\n",
    "    num_samples = len(X_)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = X_[offset:offset+batch_size]\n",
    "            batch_indexes = y_[offset:offset+batch_size]\n",
    "            images = []\n",
    "            indexes = []\n",
    "            for batch_sample in zip(batch_samples, batch_indexes):\n",
    "                name = batch_sample[0]\n",
    "#                 center_image = cv2.imread(name)\n",
    "                image = np.asarray(Image.open(name))\n",
    "                index = float(batch_sample[1])\n",
    "                if if_train:\n",
    "                    image = transform_image(image)\n",
    "                    if np.random.choice([True, False]):\n",
    "                        image = flip_image(image)\n",
    "                    image = bright_image(image)\n",
    "                    image = warp_image(image)\n",
    "                image = preprocess_image(image)\n",
    "                images.append(image)\n",
    "                indexes.append(index)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_ = np.array(images)\n",
    "            y_ = np.array(indexes)\n",
    "            yield sklearn.utils.shuffle(X_, y_)\n",
    "\n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator_samples(X_train, y_train, 32, True)\n",
    "validation_generator = generator_samples(X_test, y_test, 32, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        12832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        1056      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 64)          4160      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 1)           129       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 1, 1)           0         \n",
      "=================================================================\n",
      "Total params: 274,433\n",
      "Trainable params: 274,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzyhpcom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/tzyhpcom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, callbacks=[<keras.ca..., steps_per_epoch=15984, epochs=3, validation_steps=1776)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_7 to have 4 dimensions, but got array with shape (32, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6667757fc9dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# model.load_weights('model-09-0.0200.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mhistory_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2144\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2145\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1419\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1420\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_7 to have 4 dimensions, but got array with shape (32, 1)"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Concatenate\n",
    "from keras.layers import Cropping2D, Input\n",
    "from keras.layers import Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import tensorflow\n",
    "import cv2\n",
    "\n",
    "lamda_w = 1e-4\n",
    "\n",
    "# model = Sequential()\n",
    "input1 = Input(shape=(64, 64, 3))\n",
    "         \n",
    "conv1 = Conv2D(16, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(input1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv1)\n",
    "\n",
    "conv2 = Conv2D(32, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv1)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv2)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv3)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv4)\n",
    "\n",
    "conv5 = Conv2D(64, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv4)\n",
    "conv5 = Activation('relu')(conv5)\n",
    "\n",
    "conv6 = Conv2D(128, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv5)\n",
    "conv6 = Activation('relu')(conv6)\n",
    "\n",
    "conv7 = Conv2D(1, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv6)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "\n",
    "output = conv7\n",
    "\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=losses.sparse_categorical_crossentropy , optimizer=adam)\n",
    "model.summary()\n",
    "\n",
    "filepath=\"model/model-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# model.load_weights('model-09-0.0200.hdf5')\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch= len(X_train), \\\n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     nb_val_samples=len(X_test), \\\n",
    "                                     nb_epoch=3, verbose=1, callbacks=callbacks_list)\n",
    "model.save('model.h5') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
